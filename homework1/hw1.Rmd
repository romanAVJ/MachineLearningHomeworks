---
title: 'Tarea1: LDA'
subtitle: Román Alverto Vélez Jiménez,
          Iván Alvarez Tostado,
          Diego Villegas Juárez 
output:
  html_document:
    df_print: paged
---
```{r message=FALSE}
library(tidyverse)
library(dplyr)

#Ensure the replicability of the results
set.seed(123)
```

# Clasificación de las iris de Fisher 

El objetivo principal es _discriminar_ las clases de distintas iris de la mejor manera vía el método de aprendizaje estadístico de discriminante lineal.

Los datos están dados por la siguiente tabla

```{r}
# load iris data
iris %>% head() %>% knitr::kable()



```


## Subtarea 1: Probabilidades a priori de las clases

Primero obtendremos $\hat\pi_{k}$, la probabilidad a priori de cada clase

```{r function_apriori}
# function that estimates the apriori probability 
apriori <- function(df, column, class.name){
  pi.k <- mean(df[column] == class.name) 
  return(pi.k)
}
```

Veamos como se distribuyen los casos
```{r}
iris %>% count(Species) %>% knitr::kable()

```

## Subtarea2: Estimación de la media
En esta tarea, al suponer que $X_{k} \sim \mathcal{N}_4(\mu_k, \Sigma) \quad \forall k = 1,2,3$, encontraremos $\hat\mu_k$ vía el estimador máximo verosímil.

```{r function_media}
media <- function(df, column, class.name, vars.list){
  # get only the data of the class to estimate
  df.class <- df[df[,column] == class.name,]
  
  # get variables
  vars.vec <- unlist(vars.list)
  df.class <- df.class[,vars.vec]
  
  #estimate mean
  mean.vec <- sapply(df.class, mean)
  
  return(mean.vec)
}


```

## Subtarea3: Estimación de la covarianza


Para calcularla, usaremos el estimador máximo verosimil insesgado de la matriz de varianzas y covarianzas:
$$S_n = \frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar x)'(x_{i}- \bar x)$$

```{r}
var.covar <- function(df, column, class.name, vars.list){
  # get only the data of the class to estimate
  vars.vec <- unlist(vars.list)
  df.class <- df[df[,column] == class.name, vars.vec]

  # get variance
  Sn <- cov(df.class)
  Sn <- as.matrix(Sn)
  return(Sn)
}



```

## Subtarea4: Discriminante lineal
En esta tarea, calcularemos
$$\delta_{k}(x) = x' \Sigma^{-1}\mu_k - \frac{1}{2}\mu_k' \Sigma^{-1} \mu_k + \ln(\pi_k)$$

```{r}
delta <- function(x, apriori.k, mean.k, var.k){
  d =  t(x) %*% solve(var.k) %*% mean.k -
           1/2* t(mean.k) %*% solve(var.k) %*% mean.k +
            log(apriori.k)
  return(d)
}

```

## Subtarea5: Clasificación de observaciones
Esta función clasifica una o más de una observación y tiene como parámetros un vector con variables independientes y el dataframe sobre los que se aplican las funciones apriori, media, var.covar y delta

```{r}
clasifica<-function(X,train_df){
  #Check if data is properly given
  if (length(which(grepl(".Length", colnames(X)))) > 0 | 
      length(which(grepl(".Width", colnames(X)))) > 0) {
    test_df <- X %>% as.matrix() %>% t()
  }

  #Get the name of X variables in a list
  func_columns<-list(rownames(test_df))
  column <- "Species"
  predict_classes <- c("setosa","versicolor","virginica")
  
  # S pooled (groups of equal sizes)
  S.pooled <-  (var.covar(train_df,column, "setosa",func_columns) +
             var.covar(train_df,column, "versicolor",func_columns) +
             var.covar(train_df,column, "virginica",func_columns)) / length(unique(predict_classes))
  
  #Array with delta values for "setosa"
    setosa <- sapply(1:ncol(test_df),function(i){
    delta(test_df[,i], apriori(train_df,column,"setosa"), 
          media(train_df,column,"setosa",func_columns)
          , S.pooled)
  }) 
    
  #Array with delta values for "versicolor"
   versicolor <- sapply(1:ncol(test_df),function(i){
    delta(test_df[,i], apriori(train_df,column,"versicolor"), 
          media(train_df,column,"versicolor",func_columns)
          , S.pooled)
  }) 
  
  #Array with delta values for "virginica"
   virginica <- sapply(1:ncol(test_df),function(i){
    delta(test_df[,i], apriori(train_df,column,"virginica"), 
          media(train_df,column,"virginica",func_columns)
          , S.pooled)
  }) 
  
  #Table with delta values for each element
  df<-tibble("setosa"=setosa,"versicolor"=versicolor,"virginica"=virginica)
  max_by_row<-data.frame("Prediction" = max.col(df,'first'))
  
  for (i in 1:length(predict_classes)){
    max_by_row$Prediction[max_by_row$Prediction == i]<-predict_classes[i]
  }
  
  X <- cbind(X, max_by_row)
  return (X)
}
```

Probamos la función para sólo una observación. Tomamos los datos originales y los dividimos en: set de entrenamiento *(train_data)*: 80% de los datos, y set de pruebas *(test data)*: 20% de los datos, sin tomar en cuenta la columna *'Species'*.

```{r}

smp_size <- floor(0.8 * nrow(iris))
train_ind <- sample(seq_len(nrow(iris)), size = smp_size)

train_data <- data.frame(iris[train_ind, ])
test_data <- data.frame(iris[-train_ind, -5])
test_species <- data.frame(iris[-train_ind, ])



#Random selection of an element in iris
single_index <- sample(nrow(iris),1)  
single_data <- iris[single_index, ]
single_test <- single_data[,-5] 

#Original data for single prediction
single_data %>% knitr::kable()
```
```{r}
#LDA classification of single element
clasifica(single_test,train_data)
```


## Subtarea6: Predicciones y resultados
En esta sección aplicamos el LDA al set de entrenamiento (20% de los datos de iris) y lo comparamos con las clasificaciones verdaderas.

```{r}
cl = clasifica(test_data, train_data)
cl
```
Comparamos los resultados originales y las predicciones con una matriz de confusión:

```{r}
table <- table(test_species$Species, cl$Prediction,
               dnn = c("Actual", "Predecido"))
table
```

En este caso, vemos que, cuando incluimos todas las variables independientes ('Sepal.Length','Sepal.Width','Petal.Length','Petal.Width'), el método es capaz de clasificar fácilmente *Setosa*, pero falla en clasificar entre *Virginica* y *Versicolor*. Los niveles de accuracy, precision, recall y f1-score son:

```{r}
accuracy_overall <- sum(diag(table))
precision_overall <- diag(table) / apply(table, 2, sum) 
recall_overall <- diag(table) / apply(table, 1, sum)
f1_overall <- 2 * precision_overall * recall_overall / (precision_overall + recall_overall)

  df <- data.frame(precision_overall, recall_overall, f1_overall) %>%
  rename(Precision = precision_overall,
         Recall = recall_overall,
         F1 = f1_overall)
  df
```

Finalmente, reduciremos el número de variables independientes a 3 y 2 variables en el set de entrenamiento para ver el desempeño del algoritmo en cada caso. Utilizando las variables Petal.Length y Petal.Width para un caso, junto con Sepal.Width, Petal.Length yPetal.Width para el otro.

```{r}
#Testing data reduction
test_three <- test_data[,2:4]
test_two <- test_three[,2:3]

#LDAs
cl3 <- clasifica(test_three,train_data)
cl2 <- clasifica(test_two,train_data)

```

La matriz de confusión para 3 variables independientes es:

```{r}
table3 <- table(test_species$Species, cl3$Prediction,
               dnn = c("Actual", "Predecido"))
table3

```

Y sus métricas de desempeño son:

```{r}
accuracy_3 <- sum(diag(table3))
precision_3 <- diag(table3) / apply(table3, 2, sum) 
recall_3 <- diag(table3) / apply(table3, 1, sum)
f1_3 <- 2 * precision_3 * recall_3 / (precision_3 + recall_3)

  df3 <- data.frame(precision_3, recall_3, f1_3) %>%
  rename(Precision = precision_3,
         Recall = recall_3,
         F1 = f1_3)

```

La matriz de confusión para 2 variables independientes es:

```{r}
table2 <- table(test_species$Species, cl2$Prediction,
               dnn = c("Actual", "Predecido"))
table2

```

Y sus métricas son:

```{r}
accuracy_2 <-  sum(diag(table2))
precision_2 <- diag(table2) / apply(table2, 2, sum) 
recall_2 <- diag(table2) / apply(table2, 1, sum)
f1_2 <- 2 * precision_2 * recall_2 / (precision_2 + recall_2)

  df2 <- data.frame(precision_2, recall_2, f1_2) %>%
  rename(Precision = precision_2,
         Recall = recall_2,
         F1 = f1_2)

```
## Conclusión

En general, el LDA se desempeñó de manera consistente, independientemente del número de variables que se consideraron para el set de prueba. En los tres casos, los thresholds para **precision**, **recall** y **f1** nunca fueron más bajos que **`r min(min(df[,1]), min(df3[,1]), min(df2[,1]))`**, **`r min(min(df[,2]), min(df3[,2]), min(df2[,2]))`** y **`r min(min(df[,3]), min(df3[,3]), min(df2[,3]))`**,  correspondientemente. 




